{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a9d3c5b-7568-45d7-83ad-dee89234ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings # updated code\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import textwrap\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d615728a-4c58-4a0d-9a06-5deeb0bd7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_from_youtube_video_url(video_url):\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba1575e-a106-441a-997d-93a706caa6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=L_Guz73e6fw\"\n",
    "db = create_db_from_youtube_video_url(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006ce7ba-4d20-4aaa-a6c1-181c7e8e600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_query(db, query, k=4):\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.2)\n",
    "\n",
    "    # Template to use for the system message prompt\n",
    "    template = \"\"\"\n",
    "        You are a helpful assistant that that can answer questions about youtube videos \n",
    "        based on the video's transcript: {docs}\n",
    "        \n",
    "        Only use the factual information from the transcript to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    # Human question prompt\n",
    "    human_template = \"Answer the following question: {question}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt, human_message_prompt]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cc8696c-e369-4c17-9c45-678b1fcb8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the transcript, the video seems to be\n",
      "discussing various topics related to technological\n",
      "advancements, social divisions, human\n",
      "civilization, the creation of Wikipedia and Google\n",
      "search, the potential of GPT (a language model),\n",
      "advice for young people, consciousness, economic\n",
      "instability, and the potential impact of AGI\n",
      "(Artificial General Intelligence).\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "query = \"what is this video about?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ecbd836-ed88-478f-9ac4-08de7ac7c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The host of this podcast is Lex Fridman.\n"
     ]
    }
   ],
   "source": [
    "query = \"who was the host of this podcast?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76c68d7e-cf77-4f7f-b052-1168e3a212c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the transcript, they discussed the initial\n",
      "skepticism and mockery they faced when they\n",
      "announced their intention to work on AGI. They\n",
      "also mentioned the importance of starting to\n",
      "deploy AGI systems early while they are still\n",
      "weak, to allow for adaptation and preparation.\n",
      "They expressed concerns about the potential\n",
      "dangers and power of AGI, as well as the need for\n",
      "conversations about power, companies,\n",
      "institutions, and political systems that deploy\n",
      "and balance this power. They also mentioned the\n",
      "potential for AGI to bring positive changes and\n",
      "improve life.\n"
     ]
    }
   ],
   "source": [
    "query = \"what did talk about on AGI?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd46a6bb-ffd6-43d7-9296-44ee92d30f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the transcript, it seems that they spend\n",
      "the most time discussing the topic of artificial\n",
      "intelligence and its impact on various aspects of\n",
      "society, such as ethics, job displacement, and\n",
      "programming.\n"
     ]
    }
   ],
   "source": [
    "query = \"On what topic they spend most time?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "427b768f-b61e-4b4b-96d2-3c5baffb6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speakers in this video are Sam Altman and the\n",
      "assistant.\n"
     ]
    }
   ],
   "source": [
    "query = \"who are the speakers in this video?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da246cd8-6502-4d07-bef6-8337b7facbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are saying that Microsoft has been an amazing\n",
      "partner to them and that Satya Nadella, the CEO of\n",
      "Microsoft, has been clear, firm, and effective in\n",
      "transforming the company into a fresh, innovative,\n",
      "and developer-friendly company. They also mention\n",
      "that Microsoft understood their needs and the\n",
      "control provisions they required, which other\n",
      "companies at that scale may not have understood.\n",
      "Overall, they have a positive view of working with\n",
      "Microsoft.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are they saying about Microsoft?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "380aca57-f648-4083-96e6-a5583902db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0127a-a558-439b-b6f3-d1b99b1933be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
