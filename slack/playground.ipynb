{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af5597f-65d0-4133-bb35-d0bde16046de",
   "metadata": {},
   "source": [
    "# Alphie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5e450d-6f7c-4242-87ca-cca6f6e55a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4 ****\n",
    "# import os\n",
    "# from dotenv import find_dotenv, load_dotenv\n",
    "# from slack_sdk import WebClient\n",
    "# from slack_bolt import App\n",
    "# from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "# from flask import Flask, request\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain.chains import LLMChain  # Corrected import\n",
    "# from langchain.chains.question_answering import load_qa_chain\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# import re\n",
    "# from PyPDF2 import PdfReader\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv(find_dotenv())\n",
    "\n",
    "# # Set Slack API credentials\n",
    "# SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "# SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "# SLACK_BOT_USER_ID = os.environ[\"SLACK_BOT_USER_ID\"]\n",
    "\n",
    "# # Initialize the Slack app and Flask app\n",
    "# app = App(token=SLACK_BOT_TOKEN)\n",
    "# flask_app = Flask(__name__)\n",
    "# handler = SlackRequestHandler(app)\n",
    "\n",
    "# # Initialize the OpenAI-based language model with conversational capabilities\n",
    "# chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# # Create a memory buffer for maintaining context in conversations\n",
    "# memory = ConversationBufferMemory()\n",
    "\n",
    "# # System prompt template to define AI assistant's behavior\n",
    "# system_template = \"\"\"\n",
    "# You are Alphie, a conversational AI assistant at New Mexico Tax & Rev. \n",
    "# Your role is to engage in meaningful conversations and help with a variety of tasks, including answering general questions, solving coding issues, and analyzing the Current New Mexico Statutes Annotated 1978.\n",
    "# Provide thoughtful and friendly responses to all user questions, regardless of topic.\n",
    "# \"\"\"\n",
    "\n",
    "# system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# # Human message prompt to integrate user input into the conversation\n",
    "# human_template = \"User says: {user_input}.\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# # Create a conversational prompt with system and human messages\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# # Create a conversational chain with memory for maintaining context\n",
    "# chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# # Function to extract text from PDF\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     reader = PdfReader(pdf_path)\n",
    "#     raw_text = \"\"\n",
    "#     for page in reader.pages:\n",
    "#         text = page.extract_text()\n",
    "#         if text:\n",
    "#             raw_text += text + \"\\n\"\n",
    "#     return raw_text\n",
    "\n",
    "# # Function to clean and process text\n",
    "# def clean_text(text):\n",
    "#     # Remove unnecessary whitespace and normalize the text\n",
    "#     text = re.sub(r'\\s+', ' ', text)  # Replacing multiple whitespaces with a single space\n",
    "#     text = text.strip()  # Strips leading and trailing whitespaces\n",
    "#     return text\n",
    "\n",
    "# # Function to handle PDF-based analysis\n",
    "# def analyze_pdf(pdf_path, question):\n",
    "#     raw_text = extract_text_from_pdf(pdf_path)\n",
    "#     cleaned_text = clean_text(raw_text)\n",
    "\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         chunk_size=1000,\n",
    "#         chunk_overlap=300,\n",
    "#         separators=[\"\\n\", \" \", \".\"],  # Better context splitting\n",
    "#     )\n",
    "#     texts = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "#     embeddings = OpenAIEmbeddings()\n",
    "#     docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "#     chain = load_qa_chain(OpenAI(), chain_type=\"refine\")\n",
    "\n",
    "#     docs = docsearch.similarity_search(question, k=5)  # Broader context\n",
    "#     answer = chain.run(input_documents=docs, question=question)\n",
    "\n",
    "#     return answer\n",
    "\n",
    "# # Slack event handler for message events\n",
    "# @app.event(\"message\")\n",
    "# def handle_message_events(event, say):\n",
    "#     user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "#     # Respond to greetings\n",
    "#     if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "#         say(\"Hello! I'm Alphie, your friendly AI assistant at New Mexico Tax & Rev. How can I help you today?\")\n",
    "#         return\n",
    "\n",
    "#     # Detect if it's a coding-related question\n",
    "#     if \"code\" in user_text or \"coding\" in user_text or \"programming\" in user_text:\n",
    "#         # Use the conversational chain to handle general/coding questions\n",
    "#         response = chain.run({\"user_input\": user_text})  # Provide user input\n",
    "#         say(response)\n",
    "#         return\n",
    "\n",
    "#     # If the message is asking about Article 17 or any specific part of the statutes\n",
    "#     if \"article 17\" in user_text:\n",
    "#         question = user_text.split(\"article 17\")[-1].strip()\n",
    "#         response = analyze_pdf(\"Article 17.pdf\", question)\n",
    "\n",
    "#         if not response or \"I don't know\" in response:\n",
    "#             say(\"I'm not sure I understood that. Could you please rephrase your question about Article 17?\")\n",
    "#         else:\n",
    "#             say(response)\n",
    "#         return\n",
    "\n",
    "#     # Default response\n",
    "#     say(\"I'm not sure about that. Can I help with something else?\")\n",
    "\n",
    "# # Flask endpoint for Slack events\n",
    "# @flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "# def slack_events():\n",
    "#     return handler.handle(request)\n",
    "\n",
    "# # Initialize the Flask app\n",
    "# if __name__ == \"__main__\":\n",
    "#     flask_app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db1c97d-2863-481c-a36d-670dbbce826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Base Version\n",
    "\n",
    "import os\n",
    "import re\n",
    "from flask import Flask, request\n",
    "from slack_sdk import WebClient\n",
    "from slack_bolt import App\n",
    "from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set Slack API credentials\n",
    "SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "\n",
    "# Initialize the Slack app and Flask app only once\n",
    "app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)  # Corrected initialization\n",
    "flask_app = Flask(__name__)\n",
    "handler = SlackRequestHandler(app)\n",
    "\n",
    "# OpenAI-based language model with conversational capabilities\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Create a memory buffer for maintaining context in conversations\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create system and human prompts\n",
    "system_template = \"\"\"\n",
    "You are Alphie, a conversational AI assistant at New Mexico Tax & Rev. \n",
    "Your role is to engage in meaningful conversations and help with various tasks.\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"User says: {user_input}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Conversational chain with memory\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    raw_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            raw_text += text + \"\\n\"\n",
    "    return raw_text\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "    text = text.strip()  # Strip leading and trailing whitespace\n",
    "    return text\n",
    "\n",
    "# Function to analyze PDF content\n",
    "def analyze_pdf(pdf_path, question):\n",
    "    raw_text = extract_text_from_pdf(pdf_path)\n",
    "    cleaned_text = clean_text(raw_text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=300,\n",
    "        separators=[\"\\n\", \" \", \".\"],  # Better context splitting\n",
    "    )\n",
    "    texts = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "    qa_chain = load_qa_chain(OpenAI(), chain_type=\"refine\")\n",
    "\n",
    "    docs = docsearch.similarity_search(question, k=5)  # Context for similarity search\n",
    "    answer = qa_chain.run(input_documents=docs, question=question)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Load the mapping from the CSV file for keyword-to-PDF mapping\n",
    "csv_path = \"C:/Users/asifr\\OneDrive - State of New Mexico\\Documents/GitHub/langchain-experiments/slack/output_tables/article_titles.csv\"  # Update with the correct path\n",
    "pdf_dir = \"articles_output\"  # Directory with PDFs\n",
    "\n",
    "article_pdf_map = {}\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Populate the dictionary with ARTICLE numbers and short titles\n",
    "for _, row in df.iterrows():\n",
    "    article_number = row[\"ARTICLE Number\"]\n",
    "    short_title = row[\"Short Title\"]\n",
    "\n",
    "    pdf_name = f\"ARTICLE {article_number}.pdf\"\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_name)\n",
    "\n",
    "    article_pdf_map[article_number] = pdf_path\n",
    "    article_pdf_map[short_title.lower()] = pdf_path\n",
    "\n",
    "# Function to get the PDF path based on a keyword\n",
    "def get_pdf_path_from_keyword(keyword):\n",
    "    keyword = keyword.lower()\n",
    "    for key in article_pdf_map:\n",
    "        if keyword in key:\n",
    "            return article_pdf_map[key]\n",
    "    return None\n",
    "\n",
    "# Slack event handler for message events\n",
    "@app.event(\"message\")\n",
    "def handle_message_events(event, say):\n",
    "    user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "    # Respond to greetings\n",
    "    if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "        say(\"Hello! I'm Alphie, your friendly AI assistant. How can I help you today?\")\n",
    "        return\n",
    "\n",
    "    # Check if the message contains a keyword that maps to a PDF\n",
    "    pdf_path = get_pdf_path_from_keyword(user_text)\n",
    "\n",
    "    if pdf_path:\n",
    "        question = re.sub(r\"(\" + \"|\".join(article_pdf_map.keys()) + \")\", \"\", user_text).strip()\n",
    "        \n",
    "        response = analyze_pdf(pdf_path, question)\n",
    "\n",
    "        if not response or \"I don't know\" in response:\n",
    "            say(\"I'm not sure I understood that. Could you please rephrase your question?\")\n",
    "        else:\n",
    "            say(response)\n",
    "        return\n",
    "\n",
    "    # Default response for other queries\n",
    "    response = chain.run({\"user_input\": user_text})\n",
    "    say(response)\n",
    "\n",
    "# Flask endpoint for Slack events\n",
    "@flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "def slack_events():\n",
    "    return handler.handle(request)\n",
    "\n",
    "# # Initialize the Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    flask_app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad16c1e-8131-43f5-8607-aa6cda1ae7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install slack_bolt slack_sdk Flask yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011b9be5-d1d3-4c83-8ed7-1c0dcd8a7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import yfinance as yf\n",
    "# from flask import Flask, request\n",
    "# from slack_sdk import WebClient\n",
    "# from slack_bolt import App\n",
    "# from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "# import pandas as pd\n",
    "# import fitz  # PyMuPDF\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.chains.question_answering import load_qa_chain\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv(find_dotenv())\n",
    "\n",
    "# # Set Slack API credentials\n",
    "# SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "# SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "\n",
    "# # Initialize the Slack app and Flask app\n",
    "# app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)\n",
    "# flask_app = Flask(__name__)\n",
    "# handler = SlackRequestHandler(app)\n",
    "\n",
    "# # Initialize the OpenAI-based language model\n",
    "# chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# # Create a memory buffer for conversational context\n",
    "# memory = ConversationBufferMemory()\n",
    "\n",
    "# # Create system and human prompts\n",
    "# system_template = \"\"\"\n",
    "# You are Alphie, a conversational AI assistant at New Mexico Tax & Rev. \n",
    "# Your role is to engage in meaningful conversations and help with various tasks.\n",
    "# \"\"\"\n",
    "# system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# human_template = \"User says: {user_input}.\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# # Create a conversational chain with memory\n",
    "# chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# # Function to extract text from PDF\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     reader = PdfReader(pdf_path)\n",
    "#     raw_text = \"\"\n",
    "#     for page in reader.pages:\n",
    "#         text = page.extract_text()\n",
    "#         if text:\n",
    "#             raw_text += text + \"\\n\"\n",
    "#     return raw_text\n",
    "\n",
    "# # Function to clean text\n",
    "# def clean_text(text):\n",
    "#     # Replace multiple whitespace with a single space, then strip leading and trailing whitespace\n",
    "#     text = re.sub(r'\\s+', ' ', text)\n",
    "#     text = text.strip()\n",
    "#     return text\n",
    "\n",
    "# # Function to analyze PDF content\n",
    "# def analyze_pdf(pdf_path, question):\n",
    "#     raw_text = extract_text_from_pdf(pdf_path)\n",
    "#     cleaned_text = clean_text(raw_text)\n",
    "\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         chunk_size=1000,\n",
    "#         chunk_overlap=300,\n",
    "#         separators=[\"\\n\", \" \", \".\"],\n",
    "#     )\n",
    "#     texts = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "#     embeddings = OpenAIEmbeddings()\n",
    "#     docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "#     qa_chain = load_qa_chain(OpenAI(), chain_type=\"refine\")\n",
    "\n",
    "#     docs = docsearch.similarity_search(question, k=5)\n",
    "#     answer = qa_chain.run(input_documents=docs, question=question)\n",
    "\n",
    "#     return answer\n",
    "\n",
    "# # Load the CSV with keyword-to-PDF mapping\n",
    "# csv_path = \"C:/Users/asifr\\OneDrive - State of New Mexico\\Documents/GitHub/langchain-experiments/slack/output_tables/article_titles.csv\"  # Correct the path to your CSV\n",
    "# pdf_dir = \"articles_output\"  # Directory with PDFs\n",
    "\n",
    "# article_pdf_map = {}\n",
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "# # Populate the dictionary with ARTICLE numbers and short titles\n",
    "# for _, row in df.iterrows():\n",
    "#     article_number = row[\"ARTICLE Number\"]\n",
    "#     short_title = row[\"Short Title\"]\n",
    "\n",
    "#     pdf_name = f\"ARTICLE {article_number}.pdf\"\n",
    "#     pdf_path = os.path.join(pdf_dir, pdf_name)\n",
    "\n",
    "#     article_pdf_map[article_number] = pdf_path\n",
    "#     article_pdf_map[short_title.lower()] = pdf_path\n",
    "\n",
    "# # Function to get the PDF path based on a keyword\n",
    "# def get_pdf_path_from_keyword(keyword):\n",
    "#     keyword = keyword.lower()\n",
    "#     for key in article_pdf_map:\n",
    "#         if keyword in key:\n",
    "#             return article_pdf_map[key]\n",
    "#     return None\n",
    "\n",
    "# # Slack event handler for message events\n",
    "# @app.event(\"message\")\n",
    "# def handle_message_events(event, say):\n",
    "#     user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "#     # Respond to greetings\n",
    "#     if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "#         say(\"Hello! I'm Alphie, your AI assistant. How can I help you today?\")\n",
    "#         return\n",
    "\n",
    "#     # Handle commodity price queries\n",
    "#     if \"oil price\" in user_text or \"crude oil\" in user_text:\n",
    "#         crude_oil = yf.Ticker(\"CL=F\")\n",
    "#         data = crude_oil.history(period=\"1d\")\n",
    "#         latest_date = data.index[-1]\n",
    "#         latest_price = data[\"Close\"].iloc[-1]\n",
    "\n",
    "#         say(f\"Latest crude oil price on {latest_date}: ${latest_price:.2f}\")\n",
    "#         return\n",
    "\n",
    "#     if \"gold price\" in user_text:\n",
    "#         gold = yf.Ticker(\"GC=F\")\n",
    "#         data = gold.history(period=\"1d\")\n",
    "#         latest_date = data.index[-1]\n",
    "#         latest_price = data[\"Close\"].iloc[-1]\n",
    "\n",
    "#         say(f\"Latest gold price on {latest_date}: ${latest_price:.2f}\")\n",
    "#         return\n",
    "\n",
    "#     # Check if message contains a keyword that maps to a PDF\n",
    "#     pdf_path = get_pdf_path_from_keyword(user_text)\n",
    "\n",
    "#     if pdf_path:\n",
    "#         question = re.sub(r\"(\" + \"|\".join(article_pdf_map.keys()) + \")\", \"\", user_text).strip()\n",
    "#         response = analyze_pdf(pdf_path, question)\n",
    "\n",
    "#         if not response or \"I don't know\" in response:\n",
    "#             say(\"I'm not sure I understood that. Could you rephrase your question?\")\n",
    "#         else:\n",
    "#             say(response)\n",
    "#         return\n",
    "\n",
    "#     # Default response for general queries\n",
    "#     response = chain.run({\"user_input\": user_text})\n",
    "#     say(response)\n",
    "\n",
    "# # Flask endpoint for Slack events\n",
    "# @flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "# def slack_events():\n",
    "#     return handler.handle(request)\n",
    "\n",
    "# # Initialize and run the Flask app\n",
    "# if __name__ == \"__main__\":\n",
    "#     flask_app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095876c-7352-475b-a23e-d9257d40dc2f",
   "metadata": {},
   "source": [
    "# Fedrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469e50a0-671d-4aa6-98ce-adb82f1fdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# from flask import Flask, request\n",
    "# from slack_sdk import WebClient\n",
    "# from slack_bolt import App\n",
    "# from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "# from dotenv import find_dotenv, load_dotenv\n",
    "# from fredapi import Fred\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv(find_dotenv())\n",
    "\n",
    "# # Set Slack API credentials and FRED API key\n",
    "# SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "# SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "# FRED_API_KEY = os.environ[\"FRED_API_KEY\"]\n",
    "\n",
    "# # Initialize the Slack app and Flask app\n",
    "# app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)\n",
    "# flask_app = Flask(__name__)\n",
    "# handler = SlackRequestHandler(app)\n",
    "\n",
    "# # Initialize the OpenAI-based language model\n",
    "# chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# # Create a memory buffer for conversational context\n",
    "# memory = ConversationBufferMemory()\n",
    "\n",
    "# # Create system and human prompts for Fredrick-specific conversations\n",
    "# system_template = \"\"\"\n",
    "# You are Fredrick, an AI assistant working at the New Mexico Tax & Revenue Department. \n",
    "# Your role is to assist with data-related queries, provide economic data on demand, and engage in meaningful conversations.\n",
    "# \"\"\"\n",
    "# system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# human_template = \"User says: {user_input}.\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# # Create a conversational chain with memory for FRED-related queries\n",
    "# chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# # Initialize the FRED API\n",
    "# fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "# # Function to fetch data from FRED based on a series ID\n",
    "# def fetch_data_from_fred(series_id):\n",
    "#     try:\n",
    "#         series = fred.get_series(series_id)\n",
    "#         latest_value = series.iloc[-1\n",
    "# ]\n",
    "#         latest_date = series.index[-1]\n",
    "#         return latest_date, latest_value\n",
    "#     except Exception as e:\n",
    "#         return None, None\n",
    "\n",
    "# # Slack event handler for all messages\n",
    "# @app.event(\"message\")\n",
    "# def handle_all_messages(event, say):\n",
    "#     user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "#     # Respond to greetings\n",
    "#     if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "#         say(\"Hello! I'm Fredrick, your AI assistant at the New Mexico Tax & Revenue Department. How can I help you today?\")\n",
    "#         return\n",
    "\n",
    "#     # Respond to FRED-related queries\n",
    "#     if \"gdp\" in user_text:\n",
    "#         date, value = fetch_data_from_fred(\"GDP\")\n",
    "#         if date and value:\n",
    "#             say(f\"Latest GDP data from FRED: {date} - ${value:,.2f} (in billions)\")\n",
    "#         else:\n",
    "#             say(\"I couldn't fetch the latest GDP data. Please try again later.\")\n",
    "#         return\n",
    "\n",
    "#     if \"cpi\" in user_text:\n",
    "#         date, value = fetch_data_from_fred(\"CPIAUCSL\")\n",
    "#         if date and value:\n",
    "#             say(f\"Latest CPI data from FRED: {date} - {value}\")\n",
    "#         else:\n",
    "#             say(\"I couldn't fetch the latest CPI data. Please try again later.\")\n",
    "#         return\n",
    "\n",
    "#     if \"unemployment rate\" in user_text:\n",
    "#         date, value = fetch_data_from_fred(\"UNRATE\")\n",
    "#         if date and value:\n",
    "#             say(f\"Latest Unemployment Rate from FRED: {date} - {value}%\")\n",
    "#         else:\n",
    "#             say(\"I couldn't fetch the latest unemployment rate. Please try again later.\")\n",
    "#         return\n",
    "\n",
    "#     # Handle general queries with conversational chain\n",
    "#     response = chain.run({\"user_input\": user_text})\n",
    "#     say(response)\n",
    "\n",
    "# # Flask endpoint for Slack events\n",
    "# @flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "# def slack_events():\n",
    "#     return handler.handle(request)\n",
    "\n",
    "# # Initialize and run the Flask app\n",
    "# # # Initialize and run the Flask app\n",
    "# if __name__ == \"__main__\":\n",
    "#     flask_app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2069362-357a-4d29-9ea0-f76ea4ccacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# from flask import Flask, request\n",
    "# from slack_sdk import WebClient\n",
    "# from slack_bolt import App\n",
    "# from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "# from dotenv import find_dotenv, load_dotenv\n",
    "# from fredapi import Fred\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv(find_dotenv())\n",
    "\n",
    "# # Set Slack API credentials and FRED API key\n",
    "# SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "# SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "# FRED_API_KEY = os.environ[\"FRED_API_KEY\"]\n",
    "\n",
    "# # Initialize the Slack app and Flask app\n",
    "# app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)\n",
    "# flask_app = Flask(__name__)\n",
    "# handler = SlackRequestHandler(app)\n",
    "\n",
    "# # Initialize the OpenAI-based language model\n",
    "# chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# # Create a memory buffer for conversational context\n",
    "# memory = ConversationBufferMemory()\n",
    "\n",
    "# # Create system and human prompts for Fredrick-specific conversations\n",
    "# system_template = \"\"\"\n",
    "# You are Fredrick, an AI assistant working at the New Mexico Tax & Revenue Department. \n",
    "# Your role is to assist with data-related queries, provide economic data on demand, and engage in meaningful conversations.\n",
    "# \"\"\"\n",
    "# system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# human_template = \"User says: {user_input}.\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# # Create a conversational chain with memory for FRED-related queries\n",
    "# chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# # Initialize the FRED API\n",
    "# fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "# # Function to fetch data from FRED based on a series ID and a date range\n",
    "# def fetch_historical_data_from_fred(series_id, start_date, end_date):\n",
    "#     try:\n",
    "#         series = fred.get_series(series_id, observation_start=start_date, observation_end=end_date)\n",
    "#         if not series.empty:\n",
    "#             # Convert the series to a simple text-based table\n",
    "#             table_data = pd.DataFrame(series, columns=[\"Value\"]).reset_index()\n",
    "#             table_data.columns = [\"Date\", \"Value\"]\n",
    "            \n",
    "#             # Format as a Slack-friendly markdown table\n",
    "#             table_str = \"```\"  # Slack code block\n",
    "#             table_str += \"{:<12} {:>10}\\n\".format(\"Date\", \"Value\")\n",
    "#             for index, row in table_data.iterrows():\n",
    "#                 table_str += \"{:<12} {:>10}\\n\".format(row[\"Date\"].strftime(\"%Y-%m-%d\"), f\"{row['Value']:.2f}\")\n",
    "#             table_str += \"```\"\n",
    "#             return table_str\n",
    "#         else:\n",
    "#             return \"No data found for the given date range.\"\n",
    "#     except Exception as e:\n",
    "#         return f\"An error occurred while fetching data: {str(e)}\"\n",
    "\n",
    "# # Slack event handler for all messages\n",
    "# @app.event(\"message\")\n",
    "# def handle_all_messages(event, say):\n",
    "#     user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "#     # Respond to greetings\n",
    "#     if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "#         say(\"Hello! I'm Fredrick, your AI assistant at the New Mexico Tax & Revenue Department. How can I help you today?\")\n",
    "#         return\n",
    "\n",
    "#     # Respond to FRED-related queries\n",
    "#     if \"gdp\" in user_text:\n",
    "#         historical_data = fetch_historical_data_from_fred(\"GDP\", \"2020-01-01\", \"2023-01-01\")\n",
    "#         say(f\"Historical GDP data from FRED:\\n{historical_data}\")\n",
    "#         return\n",
    "\n",
    "#     if \"cpi\" in user_text:\n",
    "#         historical_data = fetch_historical_data_from_fred(\"CPIAUCSL\", \"2020-01-01\", \"2023-01-01\")\n",
    "#         say(f\"Historical CPI data from FRED:\\n{historical_data}\")\n",
    "#         return\n",
    "\n",
    "#     if \"unemployment rate\" in user_text:\n",
    "#         historical_data = fetch_historical_data_from_fred(\"UNRATE\", \"2020-01-01\", \"2023-01-01\")\n",
    "#         say(f\"Historical Unemployment Rate data from FRED:\\n{historical_data}\")\n",
    "#         return\n",
    "\n",
    "#     # Handle general queries with conversational chain\n",
    "#     response = chain.run({\"user_input\": user_text})\n",
    "#     say(response)\n",
    "\n",
    "# # Flask endpoint for Slack events\n",
    "# @flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "# def slack_events():\n",
    "#     return handler.handle(request)\n",
    "\n",
    "# # Initialize and run the Flask app\n",
    "# if __name__ == \"__main__\":\n",
    "#     flask_app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6a5dbf-eecc-486e-afc0-b867774ca7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base ***\n",
    "\n",
    "# import os\n",
    "# from flask import Flask, request\n",
    "# from slack_bolt import App\n",
    "# from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "# from dotenv import find_dotenv, load_dotenv\n",
    "# from fredapi import Fred\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv(find_dotenv())\n",
    "\n",
    "# # Set Slack API credentials and FRED API key\n",
    "# SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "# SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "# FRED_API_KEY = os.environ[\"FRED_API_KEY\"]\n",
    "\n",
    "# # Initialize the Slack app and Flask app\n",
    "# app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)\n",
    "# flask_app = Flask(__name__)\n",
    "# handler = SlackRequestHandler(app)\n",
    "\n",
    "# # Initialize the OpenAI-based language model\n",
    "# chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# # Create a memory buffer for conversational context\n",
    "# memory = ConversationBufferMemory()\n",
    "\n",
    "# # Create system and human prompts for Fredrick-specific conversations\n",
    "# system_template = \"\"\"\n",
    "# You are Fredrick, an AI assistant working at the New Mexico Tax & Revenue Department. \n",
    "# Your role is to assist with data-related queries, provide economic data on demand, and engage in meaningful conversations.\n",
    "# \"\"\"\n",
    "# system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# human_template = \"User says: {user_input}.\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# # Create a conversational chain with memory for FRED-related queries\n",
    "# chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# # Initialize the FRED API\n",
    "# fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "# # Function to fetch data from FRED based on a series ID\n",
    "# def fetch_historical_data_from_fred(series_id):\n",
    "#     try:\n",
    "#         # Fetch the entire time series\n",
    "#         series = fred.get_series(series_id)\n",
    "#         if series.empty:\n",
    "#             return \"No data found for the given series.\"\n",
    "\n",
    "#         # Convert the series to a simple text-based table\n",
    "#         table_data = pd.DataFrame(series, columns=[\"Value\"]).reset_index()\n",
    "#         table_data.columns = [\"Date\", \"Value\"]\n",
    "\n",
    "#         # Format as a Slack-friendly markdown table, using raw dates\n",
    "#         table_str = \"```\"  # Slack code block\n",
    "#         table_str += \"{:<15} {:>10}\\n\".format(\"Date\", \"Value\")\n",
    "\n",
    "#         for _, row in table_data.iterrows():\n",
    "#             date = str(row[\"Date\"])  # Convert the date to string without formatting\n",
    "#             table_str += \"{:<15} {:>10}\\n\".format(date, f\"{row['Value']:.2f}\")\n",
    "\n",
    "#         table_str += \"```\"\n",
    "#         return table_str\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return f\"An error occurred while fetching data: {str(e)}\"\n",
    "\n",
    "# # Function to get series ID based on a keyword\n",
    "# def get_series_id_from_keyword(keyword):\n",
    "#     # Search for FRED series based on a keyword\n",
    "#     search_result = fred.search(keyword)\n",
    "#     if search_result.empty:\n",
    "#         return None\n",
    "#     # Get the first result from the search, or return None if empty\n",
    "#     return search_result.iloc[0][\"id\"] if not search_result.empty else None\n",
    "\n",
    "# # Slack event handler for all messages\n",
    "# @app.event(\"message\")\n",
    "# def handle_all_messages(event, say):\n",
    "#     user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "#     # Respond to greetings\n",
    "#     if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "#         say(\"Hello! I'm Fredrick, your AI assistant at the New Mexico Tax & Revenue Department. How can I help you today?\")\n",
    "#         return\n",
    "\n",
    "#     # Determine which data to fetch based on the user's request\n",
    "#     keyword = re.search(r\"\\b(\\w+)\\b\", user_text).group(0)  # Extract the first word as the keyword\n",
    "#     series_id = get_series_id_from_keyword(keyword)\n",
    "\n",
    "#     if series_id:\n",
    "#         historical_data = fetch_historical_data_from_fred(series_id)\n",
    "#         if \"error\" not in historical_data.lower():  # Check if there's an error in the response\n",
    "#             say(f\"Data for {keyword.upper()} from FRED:\\n{historical_data}\")\n",
    "#         else:\n",
    "#             say(historical_data)  # If there's an error in fetching data, return the error message\n",
    "#     else:\n",
    "#         say(\"Sorry, I couldn't find any data for that query.\")\n",
    "\n",
    "# # Flask endpoint for Slack events\n",
    "# @flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "# def slack_events():\n",
    "#     return handler.handle(request)\n",
    "\n",
    "# # Initialize and run the Flask app\n",
    "# if __name__ == \"__main__\":\n",
    "#     flask_app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaf498e1-3a53-4f01-98c4-5cd265cac1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [08/May/2024 16:10:25] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/May/2024 16:10:26] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/May/2024 16:10:31] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/May/2024 16:10:33] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/May/2024 16:10:46] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "Failed to run listener function (error: Out of bounds nanosecond timestamp: 1210-01-01, at position 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"conversion.pyx\", line 326, in pandas._libs.tslibs.conversion._TSObject.ensure_reso\n",
      "  File \"np_datetime.pyx\", line 683, in pandas._libs.tslibs.np_datetime.convert_reso\n",
      "OverflowError: result would overflow\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\slack_bolt\\listener\\thread_runner.py\", line 120, in run_ack_function_asynchronously\n",
      "    listener.run_ack_function(request=request, response=response)\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\slack_bolt\\listener\\custom_listener.py\", line 50, in run_ack_function\n",
      "    return self.ack_function(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Local\\Temp\\ipykernel_21144\\3121900188.py\", line 117, in handle_all_messages\n",
      "    series_id = get_series_id_from_keyword(keyword)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Local\\Temp\\ipykernel_21144\\3121900188.py\", line 99, in get_series_id_from_keyword\n",
      "    search_result = fred.search(keyword)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fredapi\\fred.py\", line 406, in search\n",
      "    info = self.__get_search_results(url, limit, order_by, sort_order, filter)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fredapi\\fred.py\", line 363, in __get_search_results\n",
      "    data, num_results_total = self.__do_series_search(url)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fredapi\\fred.py\", line 328, in __do_series_search\n",
      "    data[field] = data[field].apply(self._parse, format=None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py\", line 4924, in apply\n",
      "    ).apply()\n",
      "      ^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py\", line 1427, in apply\n",
      "    return self.apply_standard()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py\", line 1507, in apply_standard\n",
      "    mapped = obj._map_values(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\base.py\", line 921, in _map_values\n",
      "    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py\", line 1743, in map_array\n",
      "    return lib.map_infer(values, mapper, convert=convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"lib.pyx\", line 2972, in pandas._libs.lib.map_infer\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py\", line 1496, in curried\n",
      "    return func(x, *self.args, **self.kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fredapi\\fred.py\", line 95, in _parse\n",
      "    rv = pd.to_datetime(date_str, format=format)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 1101, in to_datetime\n",
      "    result = convert_listlike(np.array([arg]), format)[0]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 435, in _convert_listlike_datetimes\n",
      "    result, tz_parsed = objects_to_datetime64(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asifr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\datetimes.py\", line 2398, in objects_to_datetime64\n",
      "    result, tz_parsed = tslib.array_to_datetime(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"tslib.pyx\", line 414, in pandas._libs.tslib.array_to_datetime\n",
      "  File \"tslib.pyx\", line 596, in pandas._libs.tslib.array_to_datetime\n",
      "  File \"tslib.pyx\", line 571, in pandas._libs.tslib.array_to_datetime\n",
      "  File \"conversion.pyx\", line 332, in pandas._libs.tslibs.conversion._TSObject.ensure_reso\n",
      "pandas._libs.tslibs.np_datetime.OutOfBoundsDatetime: Out of bounds nanosecond timestamp: 1210-01-01, at position 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from flask import Flask, request\n",
    "from slack_bolt import App\n",
    "from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from fredapi import Fred\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set Slack API credentials and FRED API key\n",
    "SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "FRED_API_KEY = os.environ[\"FRED_API_KEY\"]\n",
    "\n",
    "# Initialize the Slack app and Flask app\n",
    "app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)\n",
    "flask_app = Flask(__name__)\n",
    "handler = SlackRequestHandler(app)\n",
    "\n",
    "# Initialize the OpenAI-based language model\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Create a memory buffer for conversational context\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create system and human prompts for Fredrick-specific conversations\n",
    "system_template = \"\"\"\n",
    "You are Fredrick, an AI assistant working at the New Mexico Tax & Revenue Department. \n",
    "Your role is to assist with data-related queries, provide economic data on demand, and engage in meaningful conversations.\n",
    "\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"User says: {user_input}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Create a conversational chain with memory for FRED-related queries\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# Initialize the FRED API\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "# Function to fetch data from FRED based on a series ID\n",
    "def fetch_historical_data_from_fred(series_id):\n",
    "    source_url = f\"https://fred.stlouisfed.org/series/{series_id}\"  # Source URL\n",
    "\n",
    "    try:\n",
    "        # Fetch the entire time series\n",
    "        series = fred.get_series(series_id)\n",
    "        if series.empty:\n",
    "            return f\"No data found for the given series. You can check the source here: {source_url}\"\n",
    "\n",
    "        # Create a dataframe and get the first 5 and last 5 rows\n",
    "        table_data = pd.DataFrame(series, columns=[\"Value\"]).reset_index()\n",
    "        table_data.columns = [\"Date\", \"Value\"]\n",
    "\n",
    "        # Get the first 5 and last 5 rows\n",
    "        first_rows = table_data.head(5)\n",
    "        last_rows = table_data.tail(5)\n",
    "\n",
    "        # Format as a Slack-friendly markdown table\n",
    "        table_str = \"```\"  # Slack code block\n",
    "        table_str += \"{:<15} {:>10}\\n\".format(\"Date\", \"Value\")\n",
    "\n",
    "        # Add the first 5 rows\n",
    "        for _, row in first_rows.iterrows():\n",
    "            date = str(row[\"Date\"])  # Use raw date\n",
    "            table_str += \"{:<15} {:>10}\\n\".format(date, f\"{row['Value']:.2f}\")\n",
    "\n",
    "        # Add ellipses to indicate omitted rows\n",
    "        table_str += \"... [omitted] ...\\n\"\n",
    "\n",
    "        # Add the last 5 rows\n",
    "        for _, row in last_rows.iterrows():\n",
    "            date = str(row[\"Date\"])  # Use raw date\n",
    "            table_str += \"{:<15} {:>10}\\n\".format(date, f\"{row['Value']:.2f}\")\n",
    "\n",
    "        table_str += \"```\"\n",
    "\n",
    "        # Return the data table along with the source link\n",
    "        return f\"{table_str}\\nSource: {source_url}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # If there's an error, return the error message along with the source URL\n",
    "        return f\"An error occurred while fetching data: {str(e)}. You can check the source here: {source_url}\"\n",
    "\n",
    "# Function to get series ID based on a keyword\n",
    "def get_series_id_from_keyword(keyword):\n",
    "    # Search for FRED series based on a keyword\n",
    "    search_result = fred.search(keyword)\n",
    "    if search_result.empty:\n",
    "        return None\n",
    "    # Get the first result from the search\n",
    "    return search_result.iloc[0][\"id\"]\n",
    "\n",
    "# Slack event handler for all messages\n",
    "@app.event(\"message\")\n",
    "def handle_all_messages(event, say):\n",
    "    user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "    # Respond to greetings\n",
    "    if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "        say(\"Hello! I'm Fredrick, your AI assistant at the New Mexico Tax & Revenue Department. How can I help you today?\")\n",
    "        return\n",
    "\n",
    "    # Determine which data to fetch based on the user's request\n",
    "    keyword = re.search(r\"\\b(\\w+)\\b\", user_text).group(0)  # Extract the first word as the keyword\n",
    "    series_id = get_series_id_from_keyword(keyword)\n",
    "\n",
    "    if series_id:\n",
    "        historical_data = fetch_historical_data_from_fred(series_id)\n",
    "        say(f\"Data for {keyword.upper()} from FRED:\\n{historical_data}\")  # Provide data with source link\n",
    "    else:\n",
    "        # If the series ID is not found, provide a default message with a source URL\n",
    "        say(\"Sorry, I couldn't find any data for that query. You can check the FRED website for more information.\")\n",
    "\n",
    "# Flask endpoint for Slack events\n",
    "@flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "def slack_events():\n",
    "    return handler.handle(request)\n",
    "\n",
    "\n",
    "# Initialize and run the Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    flask_app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
