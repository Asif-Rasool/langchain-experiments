{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1a1021-84d1-4272-bfa8-c271f49821fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs created for 59 articles in 'articles output' with names based on ARTICLE number (with spaces).\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_path = \"chapter-7-taxation-2024.pdf\"\n",
    "pdf = fitz.open(pdf_path)\n",
    "\n",
    "# Find the start of each ARTICLE and capture the ARTICLE name\n",
    "article_starts = []  # List to store the start page of each ARTICLE\n",
    "article_names = []  # List to store the names of the ARTICLES\n",
    "for i, page in enumerate(pdf):\n",
    "    # Extract the text and search for \"ARTICLE\" with a number or letter\n",
    "    text = page.get_text(\"text\")\n",
    "    if \"ARTICLE\" in text:\n",
    "        lines = text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if \"ARTICLE\" in line:\n",
    "                words = line.split()\n",
    "                if len(words) > 1 and words[0] == \"ARTICLE\":\n",
    "                    article_name = words[1]  # Get the number/letter after \"ARTICLE\"\n",
    "                    if article_name.isdigit() or (article_name[0].isdigit() and article_name[1:].isalpha()):\n",
    "                        # If found, add the index of the page and the ARTICLE name\n",
    "                        article_starts.append(i)\n",
    "                        article_names.append(article_name)\n",
    "                        break\n",
    "\n",
    "# Determine the end of each ARTICLE and create separate PDFs\n",
    "num_articles = len(article_starts)\n",
    "output_dir = \"articles output\"  # Output directory with spaces\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "for i in range(num_articles):\n",
    "    start_page = article_starts[i]\n",
    "    end_page = article_starts[i + 1] if i < num_articles - 1 else len(pdf)\n",
    "\n",
    "    # Create a new PDF document for the ARTICLE\n",
    "    article_pdf = fitz.open()  # Create a new PDF object\n",
    "    article_pdf.insert_pdf(pdf, from_page=start_page, to_page=end_page - 1)  # Add the specified page range\n",
    "\n",
    "    # Save the new ARTICLE PDF with its ARTICLE name (with spaces instead of underscores)\n",
    "    article_name = f\"ARTICLE {article_names[i]}\"\n",
    "    article_path = os.path.join(output_dir, f\"{article_name}.pdf\")\n",
    "    article_pdf.save(article_path)  # Save the new PDF without \"incremental\" option\n",
    "    article_pdf.close()  # Close the new PDF document\n",
    "\n",
    "# Close the original PDF\n",
    "pdf.close()\n",
    "\n",
    "print(f\"PDFs created for {num_articles} articles in '{output_dir}' with names based on ARTICLE number (with spaces).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5271442b-235e-43fb-9ca2-e953cb4f18dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with ARTICLE numbers and short titles saved to 'output_tables\\article_titles.csv'\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd  # For handling CSV\n",
    "import os\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_path = \"chapter-7-taxation-2024.pdf\"\n",
    "pdf = fitz.open(pdf_path)\n",
    "\n",
    "# List to store data for the table\n",
    "data = []\n",
    "\n",
    "# Find the start of each ARTICLE and capture the ARTICLE name and short title\n",
    "for i, page in enumerate(pdf):\n",
    "    # Extract the text\n",
    "    text = page.get_text(\"text\")\n",
    "    lines = text.split(\"\\n\")\n",
    "    for j, line in enumerate(lines):\n",
    "        if \"ARTICLE\" in line:\n",
    "            words = line.split()\n",
    "            if len(words) > 1 and words[0] == \"ARTICLE\":\n",
    "                article_number = words[1]\n",
    "                if article_number.isdigit() or (article_number[0].isdigit() and article_number[1:].isalpha()):\n",
    "                    # Get the next line for the short title\n",
    "                    if j + 1 < len(lines):\n",
    "                        short_title = lines[j + 1].strip()  # The next line after \"ARTICLE\"\n",
    "                    else:\n",
    "                        short_title = \"No Title\"  # If there's no next line, set a default\n",
    "                    data.append({\n",
    "                        \"ARTICLE Number\": article_number,\n",
    "                        \"Short Title\": short_title\n",
    "                    })\n",
    "                    break\n",
    "\n",
    "# Create a DataFrame for the table\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"output_tables\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the table as a CSV file\n",
    "csv_path = os.path.join(output_dir, \"article_titles.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Table with ARTICLE numbers and short titles saved to '{csv_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3db7e842-5394-452b-83ee-f3fd8683cf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fredapi\n",
      "  Downloading fredapi-0.5.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\asifr\\appdata\\roaming\\python\\python311\\site-packages (from fredapi) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\asifr\\appdata\\roaming\\python\\python311\\site-packages (from pandas->fredapi) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asifr\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas->fredapi) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asifr\\appdata\\roaming\\python\\python311\\site-packages (from pandas->fredapi) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asifr\\appdata\\roaming\\python\\python311\\site-packages (from pandas->fredapi) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asifr\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.16.0)\n",
      "Downloading fredapi-0.5.2-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: fredapi\n",
      "Successfully installed fredapi-0.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyzmq-24.0.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyzmq-24.0.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyzmq-24.0.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pyzmq-24.0.1.dist-info due to invalid metadata entry 'name'\n"
     ]
    }
   ],
   "source": [
    "!pip install fredapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e66e5cbc-73c1-485e-990a-318775b13c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Crude Oil Prices:\n",
      "1986-01-02    25.56\n",
      "1986-01-03    26.00\n",
      "1986-01-06    26.53\n",
      "1986-01-07    25.85\n",
      "1986-01-08    25.87\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from fredapi import Fred\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Your FRED API key\n",
    "FRED_API_KEY = os.getenv(\"FRED_API_KEY\")\n",
    "\n",
    "# Initialize FRED API with your API key\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "# Fetch a specific time series (example: daily crude oil prices)\n",
    "series_id = \"DCOILWTICO\"  # West Texas Intermediate (WTI) Crude Oil Prices\n",
    "oil_data = fred.get_series(series_id)  # Gets the full historical data\n",
    "\n",
    "# Output a sample of the historical data\n",
    "print(\"Historical Crude Oil Prices:\")\n",
    "print(oil_data.head())  # Display the first few records\n",
    "\n",
    "# For complete data, you can save to a CSV\n",
    "oil_data.to_csv(\"crude_oil_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616bc277-92c9-45db-aef6-84575316348a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
