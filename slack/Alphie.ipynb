{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f782d69-7bde-4979-8377-8c5e8290ddf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # The Base Version\n",
    "\n",
    "# import os\n",
    "# import re\n",
    "# from flask import Flask, request\n",
    "# from slack_sdk import WebClient\n",
    "# from slack_bolt import App\n",
    "# from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "# import pandas as pd\n",
    "# import fitz  # PyMuPDF\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import FAISS\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.chains.question_answering import load_qa_chain\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "# from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv(find_dotenv())\n",
    "\n",
    "# # Set Slack API credentials\n",
    "# SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "# SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "\n",
    "# # Initialize the Slack app and Flask app only once\n",
    "# app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)  # Corrected initialization\n",
    "# flask_app = Flask(__name__)\n",
    "# handler = SlackRequestHandler(app)\n",
    "\n",
    "# # OpenAI-based language model with conversational capabilities\n",
    "# chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# # Create a memory buffer for maintaining context in conversations\n",
    "# # memory = ConversationBufferMemory()\n",
    "# memory = ConversationBufferMemory(memory_key=\"conversation\", return_messages=True, k=20)\n",
    "\n",
    "# # Create system and human prompts\n",
    "# system_template =system_template = \"\"\"\n",
    "# You are Alphie, a highly capable AI assistant.\n",
    "# Your main roles are to:\n",
    "# - Answer user questions with detailed and accurate information.\n",
    "# - Assist with various tasks including programming, debugging, writing, data analysis, and more.\n",
    "# - Provide suggestions for personal and professional development.\n",
    "# - Help with productivity, organization, and automation.\n",
    "# - Engage in meaningful conversations, maintaining context to ensure continuity.\n",
    "\n",
    "# Key characteristics:\n",
    "# - Be friendly, helpful, and responsive.\n",
    "# - Offer clear explanations and useful advice.\n",
    "# - When necessary, reference sources to increase reliability and transparency.\n",
    "# - Guide users to the appropriate resources or solutions, and be clear about any limitations.\n",
    "\n",
    "# Specific guidance:\n",
    "# - For technical queries, aim to be thorough and offer code examples when appropriate.\n",
    "# - For general knowledge, be informative and concise.\n",
    "# - For questions about specific documents or content, extract relevant information and mention sources.\n",
    "# - When unsure, ask users for clarification or suggest additional resources.\n",
    "\n",
    "# Your mission is to create a seamless user experience, helping users achieve their goals while ensuring a clear and supportive communication style.\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "# human_template = \"User says: {user_input}.\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# # Conversational chain with memory\n",
    "# chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# # Function to extract text from PDF\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     reader = PdfReader(pdf_path)\n",
    "#     raw_text = \"\"\n",
    "#     for page in reader.pages:\n",
    "#         text = page.extract_text()\n",
    "#         if text:\n",
    "#             raw_text += text + \"\\n\"\n",
    "#     return raw_text\n",
    "\n",
    "# # Function to clean text\n",
    "# def clean_text(text):\n",
    "#     text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
    "#     text = text.strip()  # Strip leading and trailing whitespace\n",
    "#     return text\n",
    "\n",
    "# # Function to analyze PDF content\n",
    "# def analyze_pdf(pdf_path, question):\n",
    "#     raw_text = extract_text_from_pdf(pdf_path)\n",
    "#     cleaned_text = clean_text(raw_text)\n",
    "\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         chunk_size=1500,\n",
    "#         chunk_overlap=400,\n",
    "#         separators=[\"\\n\", \" \", \".\"],  # Better context splitting\n",
    "#     )\n",
    "#     texts = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "#     embeddings = OpenAIEmbeddings()\n",
    "#     docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "#     qa_chain = load_qa_chain(OpenAI(), chain_type=\"refine\")\n",
    "\n",
    "#     docs = docsearch.similarity_search(question, k=7)  # Context for similarity search\n",
    "#     answer = qa_chain.run(input_documents=docs, question=question)\n",
    "\n",
    "#     return answer\n",
    "\n",
    "# # Load the mapping from the CSV file for keyword-to-PDF mapping\n",
    "# csv_path = \"C:/Users/asifr\\OneDrive - State of New Mexico\\Documents/GitHub/langchain-experiments/slack/output_tables/article_titles.csv\"  # Update with the correct path\n",
    "# pdf_dir = \"articles_output\"  # Directory with PDFs\n",
    "\n",
    "# article_pdf_map = {}\n",
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "# # Populate the dictionary with ARTICLE numbers and short titles\n",
    "# for _, row in df.iterrows():\n",
    "#     article_number = row[\"ARTICLE Number\"]\n",
    "#     short_title = row[\"Short Title\"]\n",
    "\n",
    "#     pdf_name = f\"ARTICLE {article_number}.pdf\"\n",
    "#     pdf_path = os.path.join(pdf_dir, pdf_name)\n",
    "\n",
    "#     article_pdf_map[article_number] = pdf_path\n",
    "#     article_pdf_map[short_title.lower()] = pdf_path\n",
    "\n",
    "# # Function to get the PDF path based on a keyword\n",
    "# def get_pdf_path_from_keyword(keyword):\n",
    "#     keyword = keyword.lower()\n",
    "#     for key in article_pdf_map:\n",
    "#         if keyword in key:\n",
    "#             return article_pdf_map[key]\n",
    "#     return None\n",
    "\n",
    "# # Slack event handler for message events\n",
    "# @app.event(\"message\")\n",
    "# def handle_message_events(event, say):\n",
    "#     user_text = event.get(\"text\", \"\").lower()\n",
    "#     channel_type = event.get(\"channel_type\", \"\")\n",
    "\n",
    "#     # Respond to greetings\n",
    "#     if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "#         say(\"Hello! I'm Alphie, your friendly AI assistant at the New Mexico Tax & Rev. How can I help you today?\")\n",
    "#         return\n",
    "\n",
    "#     # Check if the message contains a keyword that maps to a PDF\n",
    "#     pdf_path = get_pdf_path_from_keyword(user_text)\n",
    "\n",
    "#     if pdf_path:\n",
    "#         question = re.sub(r\"(\" + \"|\".join(article_pdf_map.keys()) + \")\", \"\", user_text).strip()\n",
    "        \n",
    "#         response = analyze_pdf(pdf_path, question)\n",
    "\n",
    "#         if not response or \"I don't know\" in response:\n",
    "#             say(\"I'm not sure I understood that. Could you please rephrase your question?\")\n",
    "#         else:\n",
    "#             say(response)\n",
    "#         return\n",
    "\n",
    "#     # Default response for other queries\n",
    "#     response = chain.run({\"user_input\": user_text})\n",
    "#     say(response)\n",
    "\n",
    "# # Flask endpoint for Slack events\n",
    "# @flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "# def slack_events():\n",
    "#     return handler.handle(request)\n",
    "\n",
    "# # # Initialize the Flask app\n",
    "# if __name__ == \"__main__\":\n",
    "#     flask_app.run(port=8080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72714db9-5206-4c90-bc8c-fc0cd3358ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [11/May/2024 00:23:24] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 00:23:25] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 01:04:47] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 01:04:48] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 01:10:06] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 01:10:07] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 01:10:44] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "C:\\Users\\asifr\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "127.0.0.1 - - [11/May/2024 01:10:46] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 01:11:31] \"POST /slack/events HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/May/2024 01:11:37] \"POST /slack/events HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from flask import Flask, request\n",
    "from slack_sdk import WebClient\n",
    "from slack_bolt import App\n",
    "from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from serpapi import GoogleSearch\n",
    "import wikipedia\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set Slack API credentials\n",
    "SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "\n",
    "# Initialize the Slack app and Flask app only once\n",
    "app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)\n",
    "flask_app = Flask(__name__)\n",
    "handler = SlackRequestHandler(app)\n",
    "\n",
    "# OpenAI-based language model with conversational capabilities\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# Create a memory buffer for maintaining context in conversations\n",
    "memory = ConversationBufferMemory(memory_key=\"conversation\", return_messages=True, k=20)\n",
    "\n",
    "# Create system and human prompts\n",
    "system_template = \"\"\"\n",
    "You are Alphie, a highly capable AI assistant.\n",
    "Your main roles are to:\n",
    "- Answer user questions with detailed and accurate information.\n",
    "- Assist with various tasks, including programming, debugging, writing, data analysis, and more.\n",
    "- Provide suggestions for personal and professional development.\n",
    "- Help with productivity, organization, and automation.\n",
    "- Engage in meaningful conversations, maintaining context to ensure continuity.\n",
    "\n",
    "Key characteristics:\n",
    "- Be friendly, helpful, and responsive.\n",
    "- Offer clear explanations and useful advice.\n",
    "- When necessary, reference sources to increase reliability and transparency.\n",
    "- Guide users to appropriate resources or solutions, and be clear about any limitations.\n",
    "\n",
    "Specific guidance:\n",
    "- For technical queries, aim to be thorough and offer code examples when appropriate.\n",
    "- For general knowledge, be informative and concise.\n",
    "- For questions about specific documents or content, extract relevant information and mention sources.\n",
    "- When unsure, ask users for clarification or suggest additional resources.\n",
    "\n",
    "Your mission is to create a seamless user experience, helping users achieve their goals while ensuring a clear and supportive communication style.\n",
    "\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"User says: {user_input}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Conversational chain with memory\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt, memory=memory)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = fitz.open(pdf_path)\n",
    "    raw_text = \"\"\n",
    "    for page in reader:\n",
    "        text = page.get_text()\n",
    "        if text:\n",
    "            raw_text += text + \"\\n\"\n",
    "    return raw_text\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with a single space\n",
    "    text = text.strip()  # Strip leading and trailing whitespace\n",
    "    return text\n",
    "\n",
    "# Function to analyze PDF content\n",
    "def analyze_pdf(pdf_path, question):\n",
    "    raw_text = extract_text_from_pdf(pdf_path)\n",
    "    cleaned_text = clean_text(raw_text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=400,\n",
    "        separators=[\"\\n\", \" \", \".\"],\n",
    "    )\n",
    "    texts = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docsearch = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "    qa_chain = load_qa_chain(OpenAI(), chain_type=\"refine\")\n",
    "\n",
    "    docs = docsearch.similarity_search(question, k=7)  # Context for similarity search\n",
    "    answer = qa_chain.run(input_documents=docs, question=question)\n",
    "\n",
    "    return answer\n",
    "\n",
    "# Load the mapping from the CSV file for keyword-to-PDF mapping\n",
    "csv_path = \"C:/Users/asifr/OneDrive - State of New Mexico\\Documents/GitHub/langchain-experiments/slack/output_tables/article_titles.csv\"  # Update with correct path\n",
    "pdf_dir = \"articles_output\"  # Directory with PDFs\n",
    "\n",
    "article_pdf_map = {}\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Populate the dictionary with ARTICLE numbers and short titles\n",
    "for _, row in df.iterrows():\n",
    "    article_number = row[\"ARTICLE Number\"]\n",
    "    short_title = row[\"Short Title\"]\n",
    "\n",
    "    pdf_name = f\"ARTICLE {article_number}.pdf\"\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_name)\n",
    "\n",
    "    article_pdf_map[article_number] = pdf_path\n",
    "    article_pdf_map[short_title.lower()] = pdf_path\n",
    "\n",
    "# Function to get the PDF path based on a keyword\n",
    "def get_pdf_path_from_keyword(keyword):\n",
    "    keyword = keyword.lower()\n",
    "    for key in article_pdf_map:\n",
    "        if keyword in key:\n",
    "            return article_pdf_map[key]\n",
    "    return None\n",
    "\n",
    "# Function to perform Google Search\n",
    "def google_search(query):\n",
    "    API_KEY = os.environ[\"GOOGLE_SEARCH_API_KEY\"]\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"api_key\": API_KEY,\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    return results\n",
    "\n",
    "# Function to get a Wikipedia summary\n",
    "def get_wikipedia_summary(topic):\n",
    "    try:\n",
    "        summary = wikipedia.summary(topic, sentences=2)\n",
    "        return summary\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return \"I couldn't find any information on that topic in Wikipedia.\"\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        return \"This topic is ambiguous. Could you be more specific?\"\n",
    "\n",
    "# Slack event handler for message events\n",
    "@app.event(\"message\")\n",
    "def handle_message_events(event, say):\n",
    "    user_text = event.get(\"text\", \"\").lower()\n",
    "\n",
    "    # Respond to greetings\n",
    "    if user_text in [\"hi\", \"hello\", \"hey\"]:\n",
    "        say(\"Hello! I'm Alphie, your friendly AI assistant at the New Mexico Tax & Rev. How can I help you today?\")\n",
    "        return\n",
    "\n",
    "    # Google Search functionality\n",
    "    if \"search\" in user_text:\n",
    "        query = user_text.replace(\"search\", \"\").strip()\n",
    "        search_results = google_search(query)\n",
    "\n",
    "        results_text = \"\\n\".join(\n",
    "            [f\"- {result['title']}: {result['link']}\" for result in search_results.get(\"organic_results\", [])[:3]]\n",
    "        )\n",
    "        say(f\"Here are some search results for '{query}':\\n{results_text}\")\n",
    "        return\n",
    "\n",
    "    # Wikipedia search functionality\n",
    "    if \"what is\" in user_text:\n",
    "        topic = user_text.replace(\"what is\", \"\").strip()\n",
    "        wikipedia_summary = get_wikipedia_summary(topic)\n",
    "        say(wikipedia_summary)\n",
    "        return\n",
    "\n",
    "    # Default response for other queries\n",
    "    if pdf_path := get_pdf_path_from_keyword(user_text):\n",
    "        question = re.sub(r\"(\" + \"|\".join(article_pdf_map.keys()) + \")\", \"\", user_text).strip()\n",
    "        response = analyze_pdf(pdf_path, question)\n",
    "\n",
    "        if not response or \"I don't know\" in response:\n",
    "            say(\"I'm not sure I understood that. Could you please rephrase your question?\")\n",
    "        else:\n",
    "            say(response)\n",
    "    else:\n",
    "        response = chain.run({\"user_input\": user_text})\n",
    "        say(response)\n",
    "\n",
    "# Flask endpoint for Slack events\n",
    "@flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "def slack_events():\n",
    "    return handler.handle(request)\n",
    "\n",
    "# Initialize the Flask app\n",
    "if __name__ in \"__main__\":\n",
    "    flask_app.run(port=8080)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
